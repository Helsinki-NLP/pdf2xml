#!/usr/bin/env perl
#-*-perl-*-

=encoding utf-8

=head1 NAME

pdf2xml - extract text from PDF files and wraps it in XML

=head1 USAGE

 pdf2xml [OPTIONS] pdf-file > output.xml

=head2 OPTIONS

 -c ............. split strings into character sequences before finding words
 -d ............. detect language for each paragraph
 -D lang ........ ignore all paragraphs that do not match language <lang>
 -h ............. skip de-hypenation (keep hyphenated words)
 -H ............. max heap size for Java VM
 -J path ........ path to Java
 -l lexicon ..... provide a list of words or a text in the target language
 -L ............. skip lowercasing (which is switched on by default)
 -m ............. skip merging character sequences (not recommended)
 -M ............. skip paragraph merging heuristics
 -o output.xml .. output file
 -r ............. skip 'pdftotext -raw'
 -x ............. skip standard 'pdftotext'
 -X ............. use pdfXtk to convert to XHTML
 -T ............. use Apache Tika for the basic conversion (default)
 -v ............. verbose output

=head1 DESCRIPTION

pdf2xml tries to combine the output of several conversion tools in order to improve the extraction of text from PDF documents. Currently, it uses pdftotext, Apache Tika and pdfxtk. In the default mode, it calls all tools to extract text and pdfxtk is used to create the basic XML file that will be used to produce the final output. Several post-processing heuristics are implemented to split and merge character sequences in order to cleanup the text. Consider the example given below:

  raw:    <p>PRESENTATION ET R A P P E L DES PRINCIPAUX RESULTATS 9</p>
  clean:  <p>PRESENTATION ET RAPPEL DES PRINCIPAUX RESULTATS 9</p>

  raw:    <p>2. Les c r i t è r e s de choix : la c o n s o m m a t i o n 
             de c o m b u s - t ib les et l e u r moda l i t é 
             d ' u t i l i s a t i on d 'une p a r t , 
             la concen t r a t ion d ' a u t r e p a r t 16</p>

  clean:  <p>2. Les critères de choix : la consommation 
             de combustibles et leur modalité 
             d'utilisation d'une part, 
             la concentration d'autre part 16</p>

=head1 TODO

This is quite slow and loading Apache Tika for each conversion is not very efficient. Using the server mode of Apache Tika would be a solution or inline-Java and direct calls to external libraries.

=head1 SEE ALSO

Apache Tika: L<http://tika.apache.org>

The Poppler Developers - L<http://poppler.freedesktop.org>

pdfXtk L<http://sourceforge.net/projects/pdfxtk/>


=head1 COPYRIGHT AND LICENSE

Copyright (C) 2013-2018 by Joerg Tiedemann

This library is free software; you can redistribute it and/or modify
it under the same terms as Perl itself, either Perl version 5.8.8 or,
at your option, any later version of Perl 5 you may have available.

=cut

use strict;
use FindBin qw/$Bin/;
use lib ("$Bin/lib");

use Text::PDF2XML;
use Getopt::Std;
use Pod::Usage;

use vars qw($opt_c $opt_h $opt_H $opt_J $opt_L $opt_l $opt_m $opt_o 
            $opt_r $opt_T $opt_x $opt_v $opt_X $opt_M $opt_d $opt_D);

getopts('chH:J:Ll:mo:rTxXvMdD:');


my $pdf_file = shift(@ARGV) || pod2usage() && exit;
my $output = $opt_o || \*STDOUT;

## convert and print XML to STDOUT

pdf2xml( $pdf_file, 
	 output                  => $output,
	 conversion_tool         => $opt_X ? 'pdfXtk' : 'tika',
	 vocabulary              => $opt_l,
	 vocabulary_from_pdf     => $opt_x ? 0 : 1,
	 vocabulary_from_raw_pdf => $opt_r ? 0 : 1,
	 java                    => $opt_J,
	 java_heap               => $opt_H,
	 split_into_characters   => $opt_c,
	 detect_languages        => $opt_d,
	 keep_languages          => $opt_D,
	 lowercase               => $opt_L ? 0 : 1,
	 dehyphenate             => $opt_h ? 0 : 1,
	 character_merging       => $opt_m ? 0 : 1,
	 paragraph_merging       => $opt_M ? 0 : 1,
	 verbose                 => $opt_v );

__END__
